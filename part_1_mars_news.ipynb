{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 12 Challenge\n",
    "## Deliverable 1: Scrape Titles and Preview Text from Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: splinter in c:\\users\\farah\\anaconda3\\lib\\site-packages (0.18.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install splinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.5'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import webdriver_manager\n",
    "webdriver_manager.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dependencies\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from splinter import Browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting webdriver_manager\n",
      "  Downloading webdriver_manager-3.8.5-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\farah\\anaconda3\\lib\\site-packages (from webdriver_manager) (21.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\farah\\anaconda3\\lib\\site-packages (from webdriver_manager) (4.64.0)\n",
      "Requirement already satisfied: requests in c:\\users\\farah\\anaconda3\\lib\\site-packages (from webdriver_manager) (2.27.1)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-0.21.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\farah\\anaconda3\\lib\\site-packages (from packaging->webdriver_manager) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\farah\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\farah\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\farah\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\farah\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\farah\\anaconda3\\lib\\site-packages (from tqdm->webdriver_manager) (0.4.4)\n",
      "Installing collected packages: python-dotenv, webdriver-manager\n",
      "Successfully installed python-dotenv-0.21.0 webdriver-manager-3.8.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Downloading: 100%|██████████| 6.46M/6.46M [00:00<00:00, 9.05MB/s]\n"
     ]
    }
   ],
   "source": [
    "# setting up splinter\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Visit the Website\n",
    "\n",
    "1. Use automated browsing to visit the [Mars NASA news site](https://redplanetscience.com). Inspect the page to identify which elements to scrape.\n",
    "\n",
    "      > **Hint** To identify which elements to scrape, you might want to inspect the page by using Chrome DevTools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# website URL\n",
    "url = 'https://redplanetscience.com/'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping page into bs\n",
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examining results\n",
    "results = soup.find_all('div', class_='list_text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Scrape the Website\n",
    "\n",
    "Create a Beautiful Soup object and use it to extract text elements from the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "headline: NASA's Curiosity Keeps Rolling As Team Operates Rover From Home\n",
      "preview: The team has learned to meet new challenges as they work remotely on the Mars mission.\n",
      "-------------\n",
      "-------------\n",
      "headline: NASA Administrator Statement on Moon to Mars Initiative, FY 2021 Budget\n",
      "preview: Jim Bridenstine addresses NASA's ambitious plans for the coming years, including Mars Sample Return.\n",
      "-------------\n",
      "-------------\n",
      "headline: Q&A with the Student Who Named Ingenuity, NASA's Mars Helicopter\n",
      "preview: As a longtime fan of space exploration, Vaneeza Rupani appreciates the creativity and collaboration involved with trying to fly on another planet.\n",
      "-------------\n",
      "-------------\n",
      "headline: NASA's Mars Helicopter Attached to Mars 2020 Rover \n",
      "preview: The helicopter will be first aircraft to perform flight tests on another planet.\n",
      "-------------\n",
      "-------------\n",
      "headline: NASA-JPL Names 'Rolling Stones Rock' on Mars\n",
      "preview: NASA's Mars InSight mission honored one of the biggest bands of all time at Pasadena concert.\n",
      "-------------\n",
      "-------------\n",
      "headline: NASA Mars Mission Connects With Bosnian and Herzegovinian Town\n",
      "preview: A letter from NASA was presented to the mayor of Jezero, Bosnia-Herzegovina, honoring the connection between the town and Jezero Crater, the Mars 2020 rover landing site.\n",
      "-------------\n",
      "-------------\n",
      "headline: Air Deliveries Bring NASA's Perseverance Mars Rover Closer to Launch\n",
      "preview: A NASA Wallops Flight Facility cargo plane transported more than two tons of equipment — including the rover's sample collection tubes — to Florida for this summer's liftoff.\n",
      "-------------\n",
      "-------------\n",
      "headline: NASA Wins 4 Webbys, 4 People's Voice Awards\n",
      "preview: Winners include the JPL-managed \"Send Your Name to Mars\" campaign, NASA's Global Climate Change website and Solar System Interactive.\n",
      "-------------\n",
      "-------------\n",
      "headline: A Martian Roundtrip: NASA's Perseverance Rover Sample Tubes\n",
      "preview: Marvels of engineering, the rover's sample tubes must be tough enough to safely bring Red Planet samples on the long journey back to Earth in immaculate condition. \n",
      "-------------\n",
      "-------------\n",
      "headline: NASA's Mars 2020 Rover Goes Coast-to-Coast to Prep for Launch\n",
      "preview: The agency's first step in returning rocks from Mars just arrived at Kennedy Space Center. The Mars 2020 team now begins readying for a launch to the Red Planet this July.\n",
      "-------------\n",
      "-------------\n",
      "headline: Deadline Closing for Names to Fly on NASA's Next Mars Rover\n",
      "preview: You have until Sept. 30 to send your names to Mars aboard the Mars 2020 rover. \n",
      "-------------\n",
      "-------------\n",
      "headline: NASA's MAVEN Maps Winds in the Martian Upper Atmosphere that Mirror the Terrain Below and Gives Clues to Martian Climate\n",
      "preview: Researchers have created the first map of wind circulation in the upper atmosphere of a planet besides Earth, using data from NASA’s MAVEN spacecraft that were collected during the last two years.\n",
      "-------------\n",
      "-------------\n",
      "headline: HiRISE Views NASA's InSight and Curiosity on Mars\n",
      "preview: New images taken from space offer the clearest orbital glimpse yet of InSight as well as a view of Curiosity rolling along.\n",
      "-------------\n",
      "-------------\n",
      "headline: Heat and Dust Help Launch Martian Water Into Space, Scientists Find\n",
      "preview: Scientists using an instrument aboard NASA’s Mars Atmosphere and Volatile EvolutioN, or MAVEN, spacecraft have discovered that water vapor near the surface of the Red Planet is lofted higher into the atmosphere than anyone expected was possible. \n",
      "-------------\n",
      "-------------\n",
      "headline: NASA's Push to Save the Mars InSight Lander's Heat Probe\n",
      "preview: The scoop on the end of the spacecraft's robotic arm will be used to 'pin' the mole against the wall of its hole.\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "headlinelist = []\n",
    "previewlist = []\n",
    "\n",
    "# looping through returned lists\n",
    "for result in results:\n",
    "\n",
    "    # getting titles\n",
    "    headlines = result.find('div', class_='content_title').text\n",
    "    # getting preview texts\n",
    "    previewtexts = result.find('div', class_='article_teaser_body').text\n",
    "\n",
    "    headlinelist.append(headlines)\n",
    "    previewlist.append(previewtexts)\n",
    "\n",
    "    print('-------------')\n",
    "    print('headline: ' + str(headlines))\n",
    "    print('preview: ' + str(previewtexts))\n",
    "    print('-------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# closing browser\n",
    "browser.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Store the Results\n",
    "\n",
    "Extract the titles and preview text of the news articles that you scraped. Store the scraping results in Python data structures as follows:\n",
    "\n",
    "* Store each title-and-preview pair in a Python dictionary. And, give each dictionary two keys: `title` and `preview`. An example is the following:\n",
    "\n",
    "  ```python\n",
    "  {'title': \"Mars Rover Begins Mission!\", \n",
    "        'preview': \"NASA's Mars Rover begins a multiyear mission to collect data about the little-explored planet.\"}\n",
    "  ```\n",
    "\n",
    "* Store all the dictionaries in a Python list.\n",
    "\n",
    "* Print the list in your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the dictionaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the text elements\n",
    "# Extract the title and preview text from the elements\n",
    "# Store each title and preview pair in a dictionary\n",
    "# Add the dictionary to the list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the list to confirm success\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Step 4: Export the Data\n",
    "\n",
    "Optionally, store the scraped data in a file or database (to ease sharing the data with others). To do so, export the scraped data to either a JSON file or a MongoDB database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data to JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data to MongoDB\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
